---
title: 网络爬虫中常用的数据提取工具
date: 2021-04-05 02:08:23
tags:
  - Python
  - Scrapy
categories:
  - 网络爬虫
---

在网络爬虫开发中，需要对返回的响应内容进行分析提取，常见的工具主要有 Beautiful Soup、PyQuery 以及框架 Scrapy 自带的 Selector，他们之间有何区别以及新上手开发爬虫该如何选择呢？

### Beautiful Soup 和 pyQuery

Beautiful Soup 目前最新版本为 bs4，和 PyQuery 对比，在使用中二者语法大同小异，如下代码所示：

```python
# Beautiful Soup4
from bs4 import BeautifulSoup

from ..items import BlogsItem

def parse_item(self,response):
    soup=BeautifulSoup(response.body,'html.parser')
    item=BlogsItem()
    item['title']=soup.select('#mainContent .postTitle2.vertical-middle').text()
    item['description']=soup.select('#mainContent .c_b_p_desc).text()
    item['pub_date']=soup.select('#mainContent .dayTitle>span).text()
```

<!-- more -->

```python
# PyQuery
from pyQuery import PyQuery as pq

from ..items import BlogsItem

def parse_item(self,response):
    doc=pq(response.body)
    item=BlogsItem()
    item['title']=doc('#mainContent .postTitle2.vertical-middle').text()
    item['description']=doc('#mainContent .c_b_p_desc').text()
    item['pub_date']=doc('#mainContent .dayTitle>span').text()
```

相对于 PyQuery 而言，Beautiful Soup 年代更久远，成熟度更高，文档完善，但是其性能较差，尤其在爬取任务量巨大(爬取量在万级以上)时，会有比较明显的速度滞后感，而且对内存的消耗也比较大。PyQuery 比 bs4 性能要更好一些，而且其提供类似 jQuery 的语法，对于熟悉前端技术的用户来说非常容易上手。

### Scrapy Selector

除了上述两种流行的第三方库，在爬虫框架 Scrapy 中还原生提供了两种选择器：XPath 和 CSS。

1. XPath

   XPath，全称 XML Path Language，即 XML 路径语言。XPath 用于在 XML 文档中通过元素和属性进行导航，同样适用于 HTML。

   XPath 使用路径表达式在文档中进行导航，语法简介明了，并且包含有超过 100 个内建函数用于字符串、数值、日期和时间比较，以及节点处理、序列处理、逻辑值判断等，XPath 也是一个 W3C 标准。

   使用 XPath 几乎可以准确定位所有节点。

   XPath 的常用规则主要是：

   - nodename：选取此节点的所有子节点
   - /：从当前节点选取直接子节点
   - //：从当前节点选取子孙节点
   - .：选取当前节点
   - ..：选取当前节点的父节点
   - @：选取属性，也可以进行属性匹配，如 div[@id="post_title"]
   - text()：获取文本
   - contains()：属性多值匹配，如 div[contains(@id,"post_title")]
   - [and]：多属性匹配，如 div[contains(@id,"post_title") and @class="post-item"]

   XPath 的常用运算符：

   - or：逻辑或
   - and：逻辑与
   - mod：求余数
   - |：求节点集
   - +/-/\*/div：加减乘除
   - =/!=：等于、不等于
   - < /<= / > / >=：小于、小于等于，大于，大于等于

   XPath 还支持按序选择：

   - '//li[1]/text()'：获取第一个 li
   - '//li[last()]/text()'：获取最后一个 li
   - '//li[position()<3]/text()'：获取前 2 个 li
   - '//li[last()-2]/text()'：获取倒数第二个 li

   更多的使用方法可以查阅 XPath 相关文档，下面是一个使用示例，从[博客园](https://www.cnblogs.com)的[精华](https://www.cnblog.com/pick/)频道爬取文章标题、内容摘要、作者和发布时间：

   ```python
   # -*- coding: utf-8 -*-
   import scrapy

   class BlogsSpider(scrapy.Spider):
       name = 'blogs'
       # allowed_domains = ['zzk.cnblogs.com/']
       start_urls = ['https://www.cnblogs.com/pick/']

       def parse(self, response):
           # use xpath selector
           for post in response.xpath('//div[@id="post_list"]//article[has-class("post-item")]'):
               title = post.xpath('.//a[has-class("post-item-title")]/text()').get()
               link = post.xpath('.//a[has-class("post-item-title")]/@href').get()
               summary = post.xpath('.//p[has-class("post-item-summary")]/text()').getall()[-1].strip()
               author = post.xpath('.//a[has-class("post-item-author")]/span/text()').get()
               publish = post.xpath('.//span[has-class("post-meta-item")]/span/text()').get()
               next_page_url = response.xpath('//div[@id="pager_bottom"]//a/@href')[-1]
               yield {'文章标题': title, '原文链接': link, '内容摘要': summary, '作者': author, '发布时间': publish}
               if next_page_url is not None:
                   yield response.follow(next_page_url, callback=self.parse)
   ```

   部分爬取结果如图：

   {% asset_img result.png %}

2. CSS

   如果你不懂 XPath 语法，还可以使用 CSS 选择器，CSS 选择器拥有接近于 XPath 选择器的速度，因为 Scrapy 会将 CSS 选择器转换为 XPath。在 scrapy.Selector.css 方法中会调用 Selector 的内部方法\_css2xpath，这是一个自动将 css 选择器语法转换成 xpath 语法的私有方法。

   下面是使用 css 选择器语法改写上面的例子：

   ```python
   # -*- coding: utf-8 -*-
   import scrapy


   class BlogsSpider(scrapy.Spider):
       name = 'blogs'
       # allowed_domains = ['zzk.cnblogs.com/']
       start_urls = ['https://www.cnblogs.com/pick/']

       def parse(self, response):
           # use css selector
           for post in response.css('div#post_list article.post-item'):
               title = post.css('a.post-item-title::text').get()
               link = post.css('a.post-item-title::attr(href)').get()
               summary = post.css('p.post-item-summary::text').getall()[-1].strip()
               author = post.css('a.post-item-author>span::text').get()
               publish = post.css('span.post-meta-item>span::text').get()
               next_page_url = response.css('div#pager_bottom a::attr(href)')[-1]
               yield {'文章标题': title, '原文链接': link, '内容摘要': summary, '作者': author, '发布时间': publish}
               if next_page_url is not None:
                   yield response.follow(next_page_url, callback=self.parse)

   ```

### 总结

如果使用 Scrapy 进行爬虫开发，推荐使用 Scrapy 提供的 XPath 选择器或者 CSS 选择器，无需额外引入第三方库，并且速度很快。而在 Beautiful Soup 和 PyQuery 之间，可以选择性能更好的 PyQuery，对于有 jQuery 使用经验的用户来说尤其方便快速上手。
